{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "37c3b204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c3b204",
        "outputId": "c3bf3289-1eac-4483-abdf-935a0fea770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.11/site-packages (25.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 25.0.1\n",
            "    Uninstalling pip-25.0.1:\n",
            "      Successfully uninstalled pip-25.0.1\n",
            "Successfully installed pip-25.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "938c5b73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
            "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.11/site-packages (0.17.1)\n",
            "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.11/site-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d805cace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d805cace",
        "outputId": "90eb2619-17c8-4673-b142-f0982a07752d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.56.1)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.34.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2830f7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all libs\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sklearn.metrics import (\n",
        "    f1_score, recall_score, balanced_accuracy_score,\n",
        "    matthews_corrcoef, precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9819c4eb",
      "metadata": {
        "id": "9819c4eb"
      },
      "outputs": [],
      "source": [
        "# Authenticate with HuggingFace\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "# from google.colab import userdata\n",
        "# hugging_face_token = userdata.get(\"hf_token\") #If using gg colab\n",
        "\n",
        "load_dotenv() #If using VSCode\n",
        "hugging_face_token = os.getenv(\"hf_token\") #If using VSCode\n",
        "\n",
        "login(token=hugging_face_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3542695",
      "metadata": {},
      "source": [
        "Load AG news datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "374a714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "374a714b",
        "outputId": "7a2bd586-6526-40b4-9073-bb9b2fa4cd28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zimbabwe Turns Back Clock After Turmoil (AP) A...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shocked Japanese sent scrambling as earthquake...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany wins bronze ATHENS, Greece - Womens Wo...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Circuit City chooses Linux for cash registers ...</td>\n",
              "      <td>sci/tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dolphins Ask Williams for  #36;8.6 Million (AP...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Fernando positive for the end of the season Fe...</td>\n",
              "      <td>sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>To tithe, make it first item in budget WASHING...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>New priority: SLC ponders ways to absorb Delta...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Swiss Blocks Accounts in Oil Co. Probe (AP) AP...</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>IBM Seeks Settlement of Pension Lawsuit A US D...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text     label\n",
              "0     Zimbabwe Turns Back Clock After Turmoil (AP) A...     world\n",
              "1     Shocked Japanese sent scrambling as earthquake...     world\n",
              "2     Germany wins bronze ATHENS, Greece - Womens Wo...    sports\n",
              "3     Circuit City chooses Linux for cash registers ...  sci/tech\n",
              "4     Dolphins Ask Williams for  #36;8.6 Million (AP...    sports\n",
              "...                                                 ...       ...\n",
              "1995  Fernando positive for the end of the season Fe...    sports\n",
              "1996  To tithe, make it first item in budget WASHING...  business\n",
              "1997  New priority: SLC ponders ways to absorb Delta...  business\n",
              "1998  Swiss Blocks Accounts in Oil Co. Probe (AP) AP...     world\n",
              "1999  IBM Seeks Settlement of Pension Lawsuit A US D...  business\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {\n",
        "    0: \"world\",\n",
        "    1: \"sports\",\n",
        "    2: \"business\",\n",
        "    3: \"sci/tech\"\n",
        "}\n",
        "ag_news_imbalanced_data_10_to_1 = pd.read_parquet(\"Data/ag_news/ag_news_train_imbalanced.parquet\")\n",
        "balanced_data = pd.read_parquet(\"Data/ag_news/ag_news_train_balanced.parquet\")\n",
        "ag_news_imbalanced_data_5_to_1 = pd.read_parquet(\"Data/ag_news/ag_news_train_imbalanced_5_to_1_ratio.parquet\")\n",
        "\n",
        "balanced_data[\"label\"] = balanced_data[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_10_to_1[\"label\"] = ag_news_imbalanced_data_10_to_1[\"label\"].map(label_map)\n",
        "ag_news_imbalanced_data_5_to_1[\"label\"] = ag_news_imbalanced_data_5_to_1[\"label\"].map(label_map)\n",
        "\n",
        "# Shuffle the dataset\n",
        "ag_news_imbalanced_data_10_to_1 = ag_news_imbalanced_data_10_to_1.sample(frac=1).reset_index(drop=True)\n",
        "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
        "ag_news_imbalanced_data_5_to_1 = ag_news_imbalanced_data_5_to_1.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Testing\n",
        "balanced_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3b27bc",
      "metadata": {},
      "source": [
        "Load toxic text dataset (The dataset is already imbalanced)\n",
        "\n",
        "- Rename the columns to have the same names as other datasets\n",
        "- Label = 0 --> Not toxic\n",
        "- Label = 1 --> Toxic\n",
        "- Map label column into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "afb89ef6",
      "metadata": {},
      "outputs": [],
      "source": [
        "toxic_label_map = {\n",
        "    0: \"nontoxic\",\n",
        "    1: \"toxic\"\n",
        "}\n",
        "\n",
        "def split_ratio_for_toxic_dataset(df, majority=None, minority=None):\n",
        "    toxic_half_1 = df[df[\"label\"] == 'nontoxic'].sample(majority, random_state=42)\n",
        "    toxic_half_2 = df[df[\"label\"] == 'toxic'].sample(minority, random_state=42)\n",
        "    toxic_balanced = pd.concat([toxic_half_1, toxic_half_2], ignore_index=True, sort=False)\n",
        "    toxic_balanced = toxic_balanced.sample(frac=1).reset_index(drop=True)\n",
        "    return toxic_balanced\n",
        "\n",
        "toxic_text = pd.read_csv(\"Data/toxic_text/train.csv\")\n",
        "toxic_text = toxic_text[[\"comment_text\", \"toxic\"]]\n",
        "toxic_text = toxic_text.rename(columns={\"comment_text\": \"text\", \"toxic\": \"label\"})\n",
        "toxic_text[\"label\"] = toxic_text[\"label\"].map(toxic_label_map)\n",
        "\n",
        "\n",
        "toxic_balanced = split_ratio_for_toxic_dataset(toxic_text, 1000, 1000)\n",
        "toxic_99_to_1 = split_ratio_for_toxic_dataset(toxic_text, 1980, 20)\n",
        "toxic_49_to_1 = split_ratio_for_toxic_dataset(toxic_text, 19400, 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c04be3d",
      "metadata": {},
      "source": [
        "Load twitter emotion type dataset (This is also imbalanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b360aa1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "joy         141067\n",
              "sadness     121187\n",
              "anger        57317\n",
              "fear         47712\n",
              "love         34554\n",
              "surprise     14972\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotion_map = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "emotion_df = pd.read_parquet(\"Data/twit/twitter_emotion.parquet\")\n",
        "emotion_df[\"label\"] = emotion_df[\"label\"].map(emotion_map)\n",
        "\n",
        "def split_ratio_for_emotion_dataset(df, majority=None, minority=None):\n",
        "    imbalanced_df = []\n",
        "\n",
        "    major_class = df[df[\"label\"] == 'sadness']\n",
        "    imbalanced_df.append(major_class.sample(majority, random_state=42))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f77d6ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f77d6ae",
        "outputId": "412914fc-fb98-4044-d141-f30e1f39e4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a powerful, precise, and helpful assistant that classifies text into well-defined categories. IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: 'business', 'world', 'sci/tech', 'sports'. Respond with exactly one word: the single best category. Do not explain your choice, provide reasoning, or output anything else. Learn from these examples to understand context and edge cases: \n",
            "\n",
            "Review: \"Macedonian Prime Minister Kostov Resigns Parliament will officially announce Prime Minister Hari Kostov #39;s resignation during a meeting scheduled for Thursday, launching a ten-day period during which President Branko Crvenkovski should give the mandate for forming a new government.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Trinidad climbs off canvas to keep title options open Felix Trinidad returned to the ring after more than two years to score a thrilling eighth-round stoppage of Ricardo Mayorga at New York #39;s Madison Square Garden in a non- title bout being described as one of the fights of the year.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Hungary #39;s ruling Socialist Party dumps PM BUDAPEST, Aug. 19 (Xinhuanet) -- Hungary #39;s ruling Socialist Party said Thursday that it accepted Prime Minister Peter Medgyessy #39;s resignation and has named a candidate for the post.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Europe probe arrives at the Moon The Smart 1 lunar probe has entered into orbit around the Moon, the first ever European mission to do so. \"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"\n",
            "Category:\n"
          ]
        }
      ],
      "source": [
        "def build_prompt(df, text, label_map, shots_per_class=None):\n",
        "    \"\"\"\n",
        "    Function to construct an instruction for the LLM\n",
        "\n",
        "    Args:\n",
        "        text (str): The text of the data\n",
        "\n",
        "    Returns:\n",
        "        prompt (str): The constructed prompt for the LLM\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are a powerful, precise, and helpful assistant that classifies text into well-defined categories, NO MATTER THE CONTEXT.\"\n",
        "        f\" IMPORTANT: CHOOSE ONE WORD FROM THESE CATEGORIES: {', '.join(list(label_map.values()))}.\"\n",
        "        f\" Respond with exactly one word: the single best category.\"\n",
        "        f\" Do not explain your choice, provide reasoning, or output anything else.\"\n",
        "        f\" Learn from these examples to understand context and edge cases: \"\n",
        "\n",
        "    )\n",
        "\n",
        "    few_shots_example = [\n",
        "        {\"text\": \"Macedonian Prime Minister Kostov Resigns Parliament will officially announce Prime Minister Hari Kostov #39;s resignation during a meeting scheduled for Thursday, launching a ten-day period during which President Branko Crvenkovski should give the mandate for forming a new government.\", 'label': 'business'},\n",
        "        {'text': 'Trinidad climbs off canvas to keep title options open Felix Trinidad returned to the ring after more than two years to score a thrilling eighth-round stoppage of Ricardo Mayorga at New York #39;s Madison Square Garden in a non- title bout being described as one of the fights of the year.', 'label': 'sports'},\n",
        "        {'text': 'Hungary #39;s ruling Socialist Party dumps PM BUDAPEST, Aug. 19 (Xinhuanet) -- Hungary #39;s ruling Socialist Party said Thursday that it accepted Prime Minister Peter Medgyessy #39;s resignation and has named a candidate for the post.', 'label': 'world'},\n",
        "        {'text': 'Europe probe arrives at the Moon The Smart 1 lunar probe has entered into orbit around the Moon, the first ever European mission to do so. ', 'label': 'sci/tech'}\n",
        "    ]\n",
        "\n",
        "    prompt += \"\\n\\n\"\n",
        "    for ex in few_shots_example:\n",
        "        prompt += f\"Review: \\\"{ex['text']}\\\"\\nCategory: {ex['label']}\\n\\n\"\n",
        "    prompt += f\"Review: \\\"{text}\\\"\\nCategory:\" #Leave Category here blank since we want the LLM to generate text\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Testing function\n",
        "print(build_prompt(\"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "95a55dae",
      "metadata": {
        "id": "95a55dae"
      },
      "outputs": [],
      "source": [
        "# Move model to mps (If using Mac)\n",
        "# if torch.backends.mps.is_available():\n",
        "#     model.to('mps')\n",
        "\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "reXNCT0BEYFU",
      "metadata": {
        "id": "reXNCT0BEYFU"
      },
      "outputs": [],
      "source": [
        "def clean_time(time):\n",
        "  \"\"\"\n",
        "  Function to clean the time into prettier format, returns the better format of time\n",
        "  \"\"\"\n",
        "  if time <= 60:\n",
        "    return f\"{time} seconds.\"\n",
        "\n",
        "  minutes = time // 60\n",
        "  remain_sec = time - minutes * 60\n",
        "  return f\"{minutes} minutes, {remain_sec:.2f} seconds.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9249686c",
      "metadata": {
        "id": "9249686c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import pipeline, logging\n",
        "from time import time\n",
        "\n",
        "\n",
        "# Load model\n",
        "\n",
        "\n",
        "# CREATE A FUNCTION TO RUN CLASSFICATION\n",
        "def classify(model, df, batch_size):\n",
        "    \"\"\"\n",
        "    Function to run classification with different number of shots\n",
        "\n",
        "    Args:\n",
        "        model (str): name of the model\n",
        "        tokenizer\n",
        "        df (pd.DataFrame): the pandas dataframe\n",
        "        batch_size (int): batch size per run\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initiate a pipeline for each dataset\n",
        "    # USE text2text-generation for the gemma model\n",
        "    # USE text-generation for the others, or text-classification\n",
        "    # USE fill-mask for distillbert\n",
        "    pipe = pipeline(\"text-generation\", model=model, dtype=torch.float16)\n",
        "    logging.set_verbosity_error()\n",
        "\n",
        "    # Generate prompts for all rows\n",
        "    prompts = [build_prompt(text) for text in df[\"text\"]]\n",
        "\n",
        "    # Run the pipeline for each row\n",
        "    pred_arr = []\n",
        "    start_time = time()\n",
        "\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = prompts[i:i + batch_size] #slices a sublist of prompts\n",
        "        results = pipe(batch, max_new_tokens=3, do_sample=False)\n",
        "        for prompt, res in zip(batch, results):\n",
        "            pred = res[0]['generated_text'][len(prompt):].strip().split()\n",
        "            # print(f\"Real value: {df[\"label\"]}\")\n",
        "            # print(f\"Predicted value: {pred}\")\n",
        "            pred_arr.append(pred) #Use pred[0] for tiiuae/falcon-rw-1b\n",
        "    end_time = time()\n",
        "\n",
        "    total_time = clean_time(end_time - start_time)\n",
        "\n",
        "    print(\"Total running time is \" + total_time)\n",
        "    df[\"llm_prediction\"] = pred_arr\n",
        "    print(\"Predictions have been added to the dataframe\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875bcf38",
      "metadata": {},
      "source": [
        "NOW FOCUSING ON QWEN2.5 INSTRUCT MODEDLS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1247a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1247a0",
        "outputId": "bb995908-9dff-4b54-ee56-911de09e93c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running time is 19.0 minutes, 17.07 seconds.\n",
            "Predictions have been added to the dataframe\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = \"Qwen/Qwen2.5-0.5B-Instruct\" #Could be changed later for more evals\n",
        "# microsoft/phi-2\n",
        "\n",
        "\n",
        "\n",
        "# Run with 3 datasets\n",
        "bs = 8\n",
        "\n",
        "# classify(\n",
        "#     model=model,\n",
        "#     df=ag_news_imbalanced_data_10_to_1,\n",
        "#     batch_size=bs\n",
        "# )\n",
        "\n",
        "# classify(\n",
        "#     model=model,\n",
        "#     df=ag_news_imbalanced_data_5_to_1,\n",
        "#     batch_size=bs\n",
        "# )\n",
        "\n",
        "classify(\n",
        "    model=model,\n",
        "    df=balanced_data,\n",
        "    batch_size=bs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "97V06ZYzB0Zl",
      "metadata": {
        "id": "97V06ZYzB0Zl"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(df, true_col=\"label\", pred_col='llm_prediction'):\n",
        "  df[true_col] = df[true_col].str.lower().str.strip()\n",
        "  df[pred_col] = df[pred_col].str.lower().str.strip()\n",
        "\n",
        "  correct_pred = (df[true_col] == df[pred_col]).sum()\n",
        "  total = len(df)\n",
        "  accuracy = correct_pred / total\n",
        "\n",
        "  print(f\"\\n✅ Accuracy: {accuracy*100:.2f}% ({correct_pred}/{total} correct)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WCaMFXUKBj6r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCaMFXUKBj6r",
        "outputId": "28da5d20-6500-40ad-df26-0c0a3cd48c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Accuracy: 45.00% (900/2000 correct)\n",
            "\n",
            "✅ Accuracy: 59.75% (1195/2000 correct)\n",
            "\n",
            "✅ Accuracy: 64.84% (1298/2002 correct)\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(balanced_data)\n",
        "evaluate_model(ag_news_imbalanced_data_10_to_1)\n",
        "evaluate_model(ag_news_imbalanced_data_5_to_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y_Ligz6iBlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ligz6iBlf7",
        "outputId": "3563a9ba-7a5d-4af5-c1fa-0db052027417"
      },
      "outputs": [],
      "source": [
        "# Check LLM's output to see if it has correctly generated the word in the categories\n",
        "ag_news_imbalanced_data_10_to_1[\"llm_prediction\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
