{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "37c3b204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37c3b204",
        "outputId": "c3bf3289-1eac-4483-abdf-935a0fea770a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 1)) (0.34.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 4)) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 5)) (4.56.1)\n",
            "Requirement already satisfied: hf-xet in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 6)) (1.1.9)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 7)) (0.47.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r req.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r req.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r req.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r req.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r req.txt (line 3)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r req.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r req.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r req.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r req.txt (line 5)) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r req.txt (line 5)) (0.6.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r req.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r req.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r req.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r req.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r req.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r req.txt (line 1)) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r req.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d805cace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d805cace",
        "outputId": "90eb2619-17c8-4673-b142-f0982a07752d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ffae77b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ffae77b",
        "outputId": "aa53e03a-2d06-417a-f0ca-fd3a21a02f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.mps.is_available()) #if using mac\n",
        "# print(torch.cuda.is_available()) #if using GPU with cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9819c4eb",
      "metadata": {
        "id": "9819c4eb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "# from google.colab import userdata\n",
        "# hugging_face_token = userdata.get(\"hf_token\") #If using gg colab\n",
        "\n",
        "load_dotenv() #If using VSCode\n",
        "hugging_face_token = os.getenv(\"hf_token\") #If using VSCode\n",
        "\n",
        "login(token=hugging_face_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "374a714b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "374a714b",
        "outputId": "7a2bd586-6526-40b4-9073-bb9b2fa4cd28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Study claims lake on Mars was wide, deep NASA #39;s Mars rover Opportunity found evidence for a lake or sea on Mars, and new research suggests the body of water was deep, large and long-lasting.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "label_map = {\n",
        "    0: \"world\",\n",
        "    1: \"sports\",\n",
        "    2: \"business\",\n",
        "    3: \"sci/tech\"\n",
        "}\n",
        "imbalanced_data = pd.read_parquet(\"Data/ag_news_train_imbalanced.parquet\")\n",
        "balanced_data = pd.read_parquet(\"Data/ag_news_train_balanced.parquet\")\n",
        "imbalanced_data_5_to_1 = pd.read_parquet(\"Data/ag_news_train_imbalanced_5_to_1_ratio.parquet\")\n",
        "\n",
        "balanced_data[\"label\"] = balanced_data[\"label\"].map(label_map)\n",
        "imbalanced_data[\"label\"] = imbalanced_data[\"label\"].map(label_map)\n",
        "imbalanced_data_5_to_1[\"label\"] = imbalanced_data_5_to_1[\"label\"].map(label_map)\n",
        "\n",
        "# Shuffle the dataset\n",
        "imbalanced_data = imbalanced_data.sample(frac=1).reset_index(drop=True)\n",
        "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
        "imbalanced_data_5_to_1 = imbalanced_data_5_to_1.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Testing\n",
        "balanced_data[balanced_data[\"label\"] == 'sci/tech'].iloc[1][\"text\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0f77d6ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f77d6ae",
        "outputId": "412914fc-fb98-4044-d141-f30e1f39e4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a powerful, precise, and helpful assistant that classifies text into well-defined categories. Your task is to carefully analyze the meaning, tone, and intent of the given text, then select the most appropriate category. Choose only from the following categories: 'business', 'world', 'sci/tech', 'sports'. Respond with exactly one word: the single best category. Do not explain your choice, provide reasoning, or output anything else. Learn from these examples to understand context and edge cases: \n",
            "\n",
            "Review: \"Macedonian Prime Minister Kostov Resigns Parliament will officially announce Prime Minister Hari Kostov #39;s resignation during a meeting scheduled for Thursday, launching a ten-day period during which President Branko Crvenkovski should give the mandate for forming a new government.\"\n",
            "Category: business\n",
            "\n",
            "Review: \"Trinidad climbs off canvas to keep title options open Felix Trinidad returned to the ring after more than two years to score a thrilling eighth-round stoppage of Ricardo Mayorga at New York #39;s Madison Square Garden in a non- title bout being described as one of the fights of the year.\"\n",
            "Category: sports\n",
            "\n",
            "Review: \"Hungary #39;s ruling Socialist Party dumps PM BUDAPEST, Aug. 19 (Xinhuanet) -- Hungary #39;s ruling Socialist Party said Thursday that it accepted Prime Minister Peter Medgyessy #39;s resignation and has named a candidate for the post.\"\n",
            "Category: world\n",
            "\n",
            "Review: \"Europe probe arrives at the Moon The Smart 1 lunar probe has entered into orbit around the Moon, the first ever European mission to do so. \"\n",
            "Category: sci/tech\n",
            "\n",
            "Review: \"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"\n",
            "Category:\n"
          ]
        }
      ],
      "source": [
        "def build_prompt(text):\n",
        "    \"\"\"\n",
        "    Function to construct an instruction for the LLM\n",
        "\n",
        "    Args:\n",
        "        text (str): The text of the data\n",
        "\n",
        "    Returns:\n",
        "        prompt (str): The constructed prompt for the LLM\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are a powerful, precise, and helpful assistant that classifies text into well-defined categories.\"\n",
        "        f\" Your task is to carefully analyze the meaning, tone, and intent of the given text, then select the most appropriate category.\"\n",
        "        f\" Choose only from the following categories: 'business', 'world', 'sci/tech', 'sports'.\"\n",
        "        f\" Respond with exactly one word: the single best category.\"\n",
        "        f\" Do not explain your choice, provide reasoning, or output anything else.\"\n",
        "        f\" Learn from these examples to understand context and edge cases: \"\n",
        "\n",
        "    )\n",
        "\n",
        "    few_shots_example = [\n",
        "        {\"text\": \"Macedonian Prime Minister Kostov Resigns Parliament will officially announce Prime Minister Hari Kostov #39;s resignation during a meeting scheduled for Thursday, launching a ten-day period during which President Branko Crvenkovski should give the mandate for forming a new government.\", 'label': 'business'},\n",
        "        {'text': 'Trinidad climbs off canvas to keep title options open Felix Trinidad returned to the ring after more than two years to score a thrilling eighth-round stoppage of Ricardo Mayorga at New York #39;s Madison Square Garden in a non- title bout being described as one of the fights of the year.', 'label': 'sports'},\n",
        "        {'text': 'Hungary #39;s ruling Socialist Party dumps PM BUDAPEST, Aug. 19 (Xinhuanet) -- Hungary #39;s ruling Socialist Party said Thursday that it accepted Prime Minister Peter Medgyessy #39;s resignation and has named a candidate for the post.', 'label': 'world'},\n",
        "        {'text': 'Europe probe arrives at the Moon The Smart 1 lunar probe has entered into orbit around the Moon, the first ever European mission to do so. ', 'label': 'sci/tech'}\n",
        "    ]\n",
        "\n",
        "    prompt += \"\\n\\n\"\n",
        "    for ex in few_shots_example:\n",
        "        prompt += f\"Review: \\\"{ex['text']}\\\"\\nCategory: {ex['label']}\\n\\n\"\n",
        "    prompt += f\"Review: \\\"{text}\\\"\\nCategory:\" #Leave Category here blank since we want the LLM to generate text\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# Testing function\n",
        "print(build_prompt(\"Astros Rally Past the Giants With one swing of the bat, Lance Berkman revived the Houston Astros' playoff hopes - and gave the Los Angeles Dodgers a much-needed reprieve. Berkman hit a three-run homer off Dustin Hermanson, highlighting a five-run ninth inning that sent Houston to a 7-3 win over San Francisco on Thursday night...\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1fef7d7f",
      "metadata": {
        "id": "1fef7d7f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b06ccaa01c449dda026bcbb2c188d43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cef96c8835624781a7f295ebe95095d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d97126ab74514987b6117e0f53bae7fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c499070bd94e4d869929ba9f8ead637e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ee24c483fc44848b04532859285d252",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f304d4f811c43e19cc9dad8779902b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be2e9dfe2a3d46e68939cf0f3f1caf86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model = \"Qwen/Qwen2.5-0.5B\" #Could be changed later for more evals\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "95a55dae",
      "metadata": {
        "id": "95a55dae"
      },
      "outputs": [],
      "source": [
        "# Move model to mps (If using Mac)\n",
        "# if torch.backends.mps.is_available():\n",
        "#     model.to('mps')\n",
        "\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "reXNCT0BEYFU",
      "metadata": {
        "id": "reXNCT0BEYFU"
      },
      "outputs": [],
      "source": [
        "def clean_time(time):\n",
        "  \"\"\"\n",
        "  Function to clean the time into prettier format, returns the better format of time\n",
        "  \"\"\"\n",
        "  if time <= 60:\n",
        "    return f\"{time} seconds.\"\n",
        "\n",
        "  minutes = time // 60\n",
        "  remain_sec = time - minutes * 60\n",
        "  return f\"{minutes} minutes, {remain_sec:.2f} seconds.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9249686c",
      "metadata": {
        "id": "9249686c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import pipeline, logging\n",
        "from time import time\n",
        "\n",
        "\n",
        "# Load model\n",
        "\n",
        "\n",
        "# CREATE A FUNCTION TO RUN CLASSFICATION\n",
        "def classify(model, tokenizer, df, batch_size):\n",
        "    \"\"\"\n",
        "    Function to run classification on 3 datasets, using batched prediction\n",
        "\n",
        "    Args:\n",
        "        model (str): name of the model\n",
        "        tokenizer\n",
        "        df (pd.DataFrame): the pandas dataframe\n",
        "        batch_size (int): batch size per run\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Initiate a pipeline for each dataset\n",
        "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "    logging.set_verbosity_error()\n",
        "\n",
        "    # Generate prompts for all rows\n",
        "    prompts = [build_prompt(text) for text in df[\"text\"]]\n",
        "\n",
        "    # Run the pipeline for each row\n",
        "    pred_arr = []\n",
        "    start_time = time()\n",
        "\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = prompts[i:i + batch_size] #slices a sublist of prompts\n",
        "        results = pipe(batch, max_new_tokens=3, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
        "        for prompt, res in zip(batch, results):\n",
        "            pred = res[0]['generated_text'][len(prompt):].strip().split()[0]\n",
        "            pred_arr.append(pred)\n",
        "    end_time = time()\n",
        "\n",
        "    total_time = clean_time(end_time - start_time)\n",
        "\n",
        "    print(\"Total running time is \" + total_time)\n",
        "    df[\"llm_prediction\"] = pred_arr\n",
        "    print(\"Predictions have been added to the dataframe\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eb1247a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb1247a0",
        "outputId": "bb995908-9dff-4b54-ee56-911de09e93c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running time is 5.0 minutes, 50.05 seconds.\n",
            "Predictions have been added to the dataframe\n",
            "Total running time is 5.0 minutes, 50.75 seconds.\n",
            "Predictions have been added to the dataframe\n",
            "Total running time is 5.0 minutes, 51.57 seconds.\n",
            "Predictions have been added to the dataframe\n"
          ]
        }
      ],
      "source": [
        "# Run with 3 datasets\n",
        "bs = 8\n",
        "\n",
        "classify(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    df=imbalanced_data,\n",
        "    batch_size=bs\n",
        ")\n",
        "\n",
        "classify(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    df=imbalanced_data_5_to_1,\n",
        "    batch_size=bs\n",
        ")\n",
        "\n",
        "classify(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    df=balanced_data,\n",
        "    batch_size=bs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "97V06ZYzB0Zl",
      "metadata": {
        "id": "97V06ZYzB0Zl"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(df, true_col=\"label\", pred_col='llm_prediction'):\n",
        "  df[true_col] = df[true_col].str.lower().str.strip()\n",
        "  df[pred_col] = df[pred_col].str.lower().str.strip()\n",
        "\n",
        "  correct_pred = (df[true_col] == df[pred_col]).sum()\n",
        "  total = len(df)\n",
        "  accuracy = correct_pred / total\n",
        "\n",
        "  print(f\"\\n✅ Accuracy: {accuracy*100:.2f}% ({correct_pred}/{total} correct)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "WCaMFXUKBj6r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCaMFXUKBj6r",
        "outputId": "28da5d20-6500-40ad-df26-0c0a3cd48c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Accuracy: 34.60% (692/2000 correct)\n",
            "\n",
            "✅ Accuracy: 67.15% (1343/2000 correct)\n",
            "\n",
            "✅ Accuracy: 79.67% (1595/2002 correct)\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(balanced_data)\n",
        "evaluate_model(imbalanced_data)\n",
        "evaluate_model(imbalanced_data_5_to_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Y_Ligz6iBlf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ligz6iBlf7",
        "outputId": "3563a9ba-7a5d-4af5-c1fa-0db052027417"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['world', 'business', 'sports', 'sci/tech'], dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imbalanced_data_5_to_1[\"llm_prediction\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bZX24YeEdLq_",
      "metadata": {
        "id": "bZX24YeEdLq_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
