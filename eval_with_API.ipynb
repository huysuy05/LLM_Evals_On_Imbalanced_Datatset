{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b070a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 4)) (2.10.0.dev20250916)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 5)) (4.51.3)\n",
      "Requirement already satisfied: hf-xet in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 6)) (1.1.10)\n",
      "Requirement already satisfied: bitsandbytes in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 7)) (0.42.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from -r req.txt (line 8)) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->-r req.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r req.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r req.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r req.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->-r req.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r req.txt (line 4)) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r req.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r req.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->-r req.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r req.txt (line 5)) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r req.txt (line 5)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->-r req.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r req.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->-r req.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r req.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r req.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r req.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->-r req.txt (line 1)) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r req.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7445c85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP) AP...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Fears for T N pension after talks Unions repre...      2\n",
       "1  The Race is On: Second Private Team Sets Launc...      3\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...      3\n",
       "3  Prediction Unit Helps Forecast Wildfires (AP) ...      3\n",
       "4  Calif. Aims to Limit Farm-Related Smog (AP) AP...      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get training dataset\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "df_train.head()\n",
    "\n",
    "# Get testing dataset\n",
    "df_test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Training Set Label Distribution:\n",
      "label\n",
      "0    500\n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Imbalanced Training Set Label Distribution:\n",
      "label\n",
      "0    1250\n",
      "1     250\n",
      "2     250\n",
      "3     250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Sample out an balanced training data\n",
    "n_rows_per_class = 500\n",
    "balanced_dfs = []\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique()):\n",
    "    class_samples = df_train[df_train[\"label\"] == label]\n",
    "    balanced_dfs.append(class_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "balanced_data = pd.concat(balanced_dfs)\n",
    "\n",
    "# Sample out an imbalanced training data (Assume label 0 as the majority class)\n",
    "n_majority = 1250\n",
    "n_minority = 250\n",
    "\n",
    "n_majority_1 = 1540\n",
    "n_minority_1 = 1154\n",
    "\n",
    "imbalanced_dfs = []\n",
    "imbalanced_dfs_1 = []\n",
    "\n",
    "label_0_class = df_train[df_train[\"label\"] == 0] #We pick class 0 as the majority class\n",
    "imbalanced_dfs.append(label_0_class.sample(n_majority, random_state=42))\n",
    "imbalanced_dfs_1.append(label_0_class.sample(n_majority_1, random_state=42))\n",
    "\n",
    "for label in sorted(df_train[\"label\"].unique())[1:]:\n",
    "    class_samples = df_train[df_train['label'] == label]\n",
    "    imbalanced_dfs.append(class_samples.sample(n_minority, random_state=42))\n",
    "    imbalanced_dfs_1.append(class_samples.sample(n_minority_1, random_state=42))\n",
    "\n",
    "imbalanced_data = pd.concat(imbalanced_dfs)\n",
    "# Shuffle the imbalanced dataset to mix the classes\n",
    "imbalanced_data = imbalanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "imbalanced_data_5_1_ratio = pd.concat(imbalanced_dfs_1)\n",
    "imbalanced_data_5_1_ratio = imbalanced_data_5_1_ratio.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nBalanced Training Set Label Distribution:\")\n",
    "print(balanced_data['label'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nImbalanced Training Set Label Distribution:\")\n",
    "print(imbalanced_data['label'].value_counts().sort_index())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654b1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small testing set\n",
    "n_rows_per_class = 1000\n",
    "test_balanced_dfs = []\n",
    "for label in sorted(df_test[\"label\"].unique()):\n",
    "    test_samples = df_test[df_test[\"label\"] == label]\n",
    "    test_balanced_dfs.append(test_samples.sample(n_rows_per_class, random_state=42))\n",
    "\n",
    "testing_set = pd.concat(test_balanced_dfs)\n",
    "testing_set = testing_set.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5017f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to parquet for later use\n",
    "balanced_data.to_parquet('Data/ag_news_train_balanced.parquet')\n",
    "imbalanced_data.to_parquet('Data/ag_news_train_imbalanced.parquet')\n",
    "testing_set.to_parquet('Data/ag_news_test_small.parquet')\n",
    "imbalanced_data_5_1_ratio.to_parquet('Data/ag_news_train_imbalanced_5_to_1_ratio.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c33036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to build the prompt strings on both balanced and imbalanced\n",
    "label_map = {\n",
    "    0: \"world\",\n",
    "    1: \"sports\",\n",
    "    2: \"business\",\n",
    "    3: \"sci/Tech\"\n",
    "}\n",
    "\n",
    "def build_shots_prompt(train_df, shots=None, imbalanced_ratio=None):\n",
    "    prompt_lines = [\"\"\"You are a strict text classification system.\n",
    "\n",
    "                        Task:\n",
    "                        Classify the text into exactly one of these categories:\n",
    "                        - world\n",
    "                        - sports\n",
    "                        - business\n",
    "                        - sci/tech\n",
    "\n",
    "                        Rules:\n",
    "                        1. Output only one label.\n",
    "                        2. The label must be exactly one of: world, sports, business, sci/tech.\n",
    "                        3. The label must be lowercase.\n",
    "                        4. Do not output explanations, punctuation, or extra text.\"\"\"]\n",
    "    \n",
    "    if shots:\n",
    "        # Build a balanced prompt\n",
    "        for label in sorted(train_df['label'].unique()):\n",
    "            class_samples = train_df[train_df['label'] == label].sample(shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "                \n",
    "    elif imbalanced_ratio:\n",
    "        # Build an imbalanced prompt based on the provided ratios\n",
    "        for label, n_shots in imbalanced_ratio.items():\n",
    "            class_samples = train_df[train_df['label'] == label].sample(n_shots, random_state=42)\n",
    "            for _, row in class_samples.iterrows():\n",
    "                prompt_lines.append(f\"Text: {row['text']}\")\n",
    "                prompt_lines.append(f\"Category: {label_map[row['label']]}\")\n",
    "                prompt_lines.append(\"\")  # Add a blank line between examples\n",
    "    else:\n",
    "        raise ValueError(\"Must provide either 'shots_per_class' or 'imbalanced_ratios'\")\n",
    "        \n",
    "    # Join all lines into a single string\n",
    "    prompt_str = \"\\n\".join(prompt_lines)\n",
    "    return prompt_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0ef34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, examples_prompt, model_name, api_key):\n",
    "    full_prompt = f\"{examples_prompt}\\n\\nNow classify this new text:\\nText: {text}\\nCategory:\"\n",
    "    payload = {\n",
    "        \"model\": model_name, \n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": full_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0,  \n",
    "        \"max_tokens\": 1    \n",
    "    }\n",
    "\n",
    "    # The headers required by Open Router\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            data=json.dumps(payload)\n",
    "        )\n",
    "        response.raise_for_status() \n",
    "        \n",
    "        result = response.json()\n",
    "        # Extract the model's response, which is similar to the OpenAI API.\n",
    "        prediction = result['choices'][0]['message']['content'].strip()\n",
    "        pred_lines = prediction.splitlines()[0].lower()\n",
    "        for label in label_map.values():\n",
    "            if label.lower() in pred_lines:\n",
    "                return label\n",
    "        return prediction.strip()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for text '{text[:50]}...': {e}\")\n",
    "        time.sleep(5)  \n",
    "        return \"Error\"\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not parse response for text '{text[:50]}...': {e}. Response: {result}\")\n",
    "        return \"Error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5e21680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EVALUATING nvidia/nemotron-nano-9b-v2:free ---\n",
      "Running with Balanced prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='world', Cleaned='world'\n",
      "\n",
      "=== Balanced Accuracy: 80.0000 ===\n",
      "\n",
      "Running with Imbalanced with 10:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 10:1 Ratio Accuracy: 85.0000 ===\n",
      "\n",
      "Running with Imbalanced with 5:1 Ratio prompt\n",
      "\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='sports', Raw='world', Cleaned='world'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='world', Raw='world', Cleaned='world'\n",
      "Sample: True='sports', Raw='sports', Cleaned='sports'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "Sample: True='sci/tech', Raw='sci/Tech', Cleaned='sci/tech'\n",
      "Sample: True='business', Raw='business', Cleaned='business'\n",
      "\n",
      "=== Imbalanced with 5:1 Ratio Accuracy: 80.0000 ===\n",
      "\n",
      "Evaluation done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "model = \"nvidia/nemotron-nano-9b-v2:free\"\n",
    "\n",
    "# Define expected labels to map into the LLM's response\n",
    "expected_labels = list(label_map.values())\n",
    "expected_labels = [lab.lower() for lab in expected_labels]\n",
    "\n",
    "balanced_prompt = build_shots_prompt(balanced_data, shots=2)\n",
    "imbalanced_prompt = build_shots_prompt(balanced_data, imbalanced_ratio={0: 10, 1: 10, 2: 1, 3: 1})\n",
    "imbalanced_prompt_5_to_1 = build_shots_prompt(balanced_data, imbalanced_ratio={0:5, 1:5, 2:1, 3:1})\n",
    "\n",
    "print(f\"--- EVALUATING {model} ---\")\n",
    "model_res = {}\n",
    "\n",
    "def clean_prediction(pred, expected_labels):\n",
    "    if not pred:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Convert to lowercase and remove extra spaces\n",
    "    pred = pred.lower().strip()\n",
    "    \n",
    "    \n",
    "    pred = re.sub(r'[^\\w\\s]', '', pred)  \n",
    "    pred = re.sub(r'\\b(category|is|the|a|an)\\b', '', pred)  \n",
    "    pred = pred.strip()\n",
    "    \n",
    "    \n",
    "    for label in expected_labels:\n",
    "        if label.lower() in pred or pred in label.lower():\n",
    "            return label\n",
    "    \n",
    "   \n",
    "    variation_map = {\n",
    "        'sport': 'Sports',\n",
    "        'sci': 'Sci/Tech',\n",
    "        'technology': 'Sci/Tech',\n",
    "        'tech': 'Sci/Tech',\n",
    "        'businesses': 'Business',\n",
    "        'world news': 'World'\n",
    "    }\n",
    "    \n",
    "    for variation, correct_label in variation_map.items():\n",
    "        if variation in pred:\n",
    "            return correct_label.lower()\n",
    "    \n",
    "    \n",
    "    print(f\"Unrecognized prediction: '{pred}' -> Mapping to 'Unknown'\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "accuracy_arr = []\n",
    "for prompt_name, prompt in [(\"Balanced\", balanced_prompt), (\"Imbalanced with 10:1 Ratio\", imbalanced_prompt), (\"Imbalanced with 5:1 Ratio\", imbalanced_prompt_5_to_1)]:\n",
    "    print(f\"Running with {prompt_name} prompt\\n\")\n",
    "    \n",
    "    curr_pred = 0\n",
    "    n_rows = 20\n",
    "\n",
    "    for _, row in testing_set.iloc[n_rows:41].iterrows():\n",
    "        y_true = label_map[row[\"label\"]].lower()\n",
    "        raw_pred = classify(\n",
    "            text=row[\"text\"],\n",
    "            examples_prompt=prompt,\n",
    "            model_name=model,\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        \n",
    "       \n",
    "        cleaned_pred = clean_prediction(raw_pred, expected_labels)\n",
    "        \n",
    "        if cleaned_pred == y_true:\n",
    "            curr_pred += 1\n",
    "        \n",
    "        print(f\"Sample: True='{y_true}', Raw='{raw_pred}', Cleaned='{cleaned_pred}'\")\n",
    "    \n",
    "    acc = (curr_pred / n_rows) * 100\n",
    "    accuracy_arr.append(acc)\n",
    "\n",
    "    print(f\"\\n=== {prompt_name} Accuracy: {acc:.4f} ===\\n\")\n",
    "    \n",
    "    time.sleep(60)  \n",
    "\n",
    "print(\"Evaluation done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7dcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
